{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29fea05",
   "metadata": {},
   "source": [
    "B√ÄI TEST DATA ENGINEER - NEXAR GAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b1300",
   "metadata": {},
   "source": [
    "Gi·∫£i n√©n th∆∞ m·ª•c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908183ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gi·∫£i n√©n xong!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n file zip v√† th∆∞ m·ª•c gi·∫£i n√©n\n",
    "zip_path = 'drive-download-20250723T030341Z-1-001.zip'\n",
    "extract_to = 'unzipped'\n",
    "\n",
    "# Gi·∫£i n√©n\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "print(\" Gi·∫£i n√©n xong!\")\n",
    "\n",
    "# ƒê·ªçc c√°c file JSON-ND\n",
    "for filename in os.listdir(extract_to):\n",
    "    if filename.endswith(('.json', '.jsonl', '.ndjson')):\n",
    "        file_path = os.path.join(extract_to, filename)\n",
    "        print(f\"üìÑ ƒê·ªçc file: {file_path}\")\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d0d11",
   "metadata": {},
   "source": [
    "Ghi d·ªØ li·ªáu d·∫°ng json dump ƒë·ªÉ xem d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f30a251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ ghi 71273 b·∫£n ghi v√†o: /home/ittranphu/tienth/nexar/output_dump69.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON-ND gzip\n",
    "path = '/home/ittranphu/tienth/nexar/unzipped/event_dump_000000000069.json.gz'\n",
    "df = pd.read_json(path, compression='gzip', lines=True)\n",
    "\n",
    "# Chuy·ªÉn DataFrame th√†nh danh s√°ch c√°c dict (m·ªói d√≤ng l√† 1 record)\n",
    "records = df.to_dict(orient='records')\n",
    "\n",
    "# Ghi ra file JSON d·∫°ng chu·∫©n (d·∫°ng list c√°c object)\n",
    "output_path = '/home/ittranphu/tienth/nexar/output_dump69.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ ghi {len(records)} b·∫£n ghi v√†o: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a704602",
   "metadata": {},
   "source": [
    "L√†m ph·∫≥ng d·ªØ li·ªáu th√†nh d·∫°ng b·∫£ng v√† Ghi d·ªØ li·ªáu v√†o psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1122288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load c·∫£ th∆∞ m·ª•c\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#  PostgreSQL connection\n",
    "engine = create_engine('postgresql+psycopg2://tienth:tienth@localhost:5434/ke_toan_dw')\n",
    "\n",
    "#  Path to folder\n",
    "folder_path = '/home/ittranphu/tienth/nexar/unzipped'\n",
    "\n",
    "def parse_event_params(params_list):\n",
    "    flat = {}\n",
    "    for param in params_list:\n",
    "        key = param.get('key')\n",
    "        val = param.get('value', {})\n",
    "        if 'string_value' in val:\n",
    "            flat[key] = val['string_value']\n",
    "        elif 'int_value' in val:\n",
    "            try:\n",
    "                flat[key] = int(val['int_value'])\n",
    "            except ValueError:\n",
    "                flat[key] = val['int_value']\n",
    "        elif 'float_value' in val:\n",
    "            flat[key] = float(val['float_value'])\n",
    "    return flat\n",
    "\n",
    "def collect_all_keys_from_folder(folder_path, limit_per_file=100):\n",
    "    event_keys = set()\n",
    "    geo_keys = set()\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if not fname.endswith('.json.gz'):\n",
    "            continue\n",
    "        with gzip.open(os.path.join(folder_path, fname), 'rt', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= limit_per_file:\n",
    "                    break\n",
    "                record = json.loads(line)\n",
    "                event_params = parse_event_params(record.get('event_params', []))\n",
    "                event_keys.update(event_params.keys())\n",
    "                geo = record.get('geo', {})\n",
    "                geo_keys.update(geo.keys())\n",
    "    return sorted(event_keys), sorted(geo_keys)\n",
    "\n",
    "def process_record(record, event_keys, geo_keys):\n",
    "    row = {}\n",
    "    ts_micro = record.get('event_timestamp')\n",
    "    ts = None\n",
    "    if ts_micro:\n",
    "        try:\n",
    "            ts = datetime.utcfromtimestamp(int(ts_micro) / 1_000_000)\n",
    "        except:\n",
    "            ts = None\n",
    "\n",
    "    row['event_date'] = datetime.strptime(str(record.get('event_date')), \"%Y%m%d\").date() if record.get('event_date') else None\n",
    "    row['event_timestamp'] = ts\n",
    "    row['event_name'] = record.get('event_name')\n",
    "    row['user_id'] = record.get('user_id')\n",
    "\n",
    "    geo = record.get('geo', {})\n",
    "    for key in geo_keys:\n",
    "        row[f'geo_{key}'] = geo.get(key)\n",
    "\n",
    "    event_params = parse_event_params(record.get('event_params', []))\n",
    "    for key in event_keys:\n",
    "        row[key] = event_params.get(key)\n",
    "\n",
    "    return row\n",
    "\n",
    "def flatten_all_files_to_postgres(folder_path):\n",
    "    print(\" Scanning all files to collect keys...\")\n",
    "    event_keys, geo_keys = collect_all_keys_from_folder(folder_path)\n",
    "\n",
    "    base_fields = ['event_date', 'event_timestamp', 'event_name', 'user_id']\n",
    "    geo_fields = [f'geo_{k}' for k in geo_keys]\n",
    "    all_fields = base_fields + geo_fields + event_keys\n",
    "\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if not fname.endswith('.json.gz'):\n",
    "            continue\n",
    "        full_path = os.path.join(folder_path, fname)\n",
    "        print(f\" Processing file: {fname}\")\n",
    "        rows = []\n",
    "        with gzip.open(full_path, 'rt', encoding='utf-8') as fin:\n",
    "            for i, line in enumerate(fin):\n",
    "                try:\n",
    "                    record = json.loads(line)\n",
    "                    row = process_record(record, event_keys, geo_keys)\n",
    "                    rows.append(row)\n",
    "                except Exception as e:\n",
    "                    print(f\" Error in line {i} of {fname}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                if len(rows) >= 1000:\n",
    "                    df = pd.DataFrame(rows)\n",
    "                    df.to_sql(\"event_logs_flat\", engine, if_exists='append', index=False)\n",
    "                    print(f\" Inserted 1000 rows from {fname}\")\n",
    "                    rows = []\n",
    "\n",
    "            if rows:\n",
    "                df = pd.DataFrame(rows)\n",
    "                df.to_sql(\"event_logs_flat\", engine, if_exists='append', index=False)\n",
    "                print(f\" Inserted {len(rows)} final rows from {fname}\")\n",
    "\n",
    "#  Run\n",
    "if __name__ == \"__main__\":\n",
    "    flatten_all_files_to_postgres(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a2a73",
   "metadata": {},
   "source": [
    "a.T√≠nh t·ªâ l·ªá ng∆∞·ªùi ch∆°i th·∫Øng ·ªü c√°c level 1, 5, 10 cho to√†n b·ªô user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b29f2a",
   "metadata": {},
   "source": [
    "T·ªâ l·ªá ng∆∞·ªùi ch∆°i th·∫Øng ·ªü level 1 = 1 - (t·ªâ l·ªá ng∆∞·ªùi ch∆°i thua ·ªü level 1)\n",
    "\n",
    "A = S·ªë l·∫ßn ng∆∞·ªùi ch∆°i thua ·ªü level 10.\n",
    "\n",
    "B = S·ªë l·∫ßn ng∆∞·ªùi ch∆°i ch∆°i ·ªü level 10 ho·∫∑c cao h∆°n, v√† c√≥ result r√µ r√†ng (win ho·∫∑c lose).  nh·ªØng ng∆∞·ªùi ƒë√£ √≠t nh·∫•t ho√†n th√†nh level 10.\n",
    "\n",
    "T√≠nh t·ªâ l·ªá th·∫Øng = 1 - (s·ªë l·∫ßn thua ·ªü level 10 / t·ªïng s·ªë l·∫ßn ch∆°i level ‚â•10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b9ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  level_label  lose_at_level  total_after_level  win_rate\n",
      "0     level_1              0              34510   1.00000\n",
      "1     level_5             10              32237   0.99969\n",
      "2    level_10            143              29852   0.99521\n"
     ]
    }
   ],
   "source": [
    "# test v·ªõi 1 file d·ªØ li·ªáu\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ CSV\n",
    "df = pd.read_csv('/home/ittranphu/tienth/nexar/flattened_full_output.csv')\n",
    "\n",
    "# H√†m th·ª±c thi SQL\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "# Truy v·∫•n l·ªçc b·∫£n ghi\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    'level_1' AS level_label,\n",
    "    (SELECT COUNT(*) FROM df WHERE level = 1 AND result = 'lose') AS lose_at_level,\n",
    "    (SELECT COUNT(*) FROM df WHERE level >= 1 AND result IS NOT NULL) AS total_after_level,\n",
    "    CASE\n",
    "        WHEN (SELECT COUNT(*) FROM df WHERE level >= 1 AND result IS NOT NULL) = 0 THEN 0\n",
    "        ELSE 1.0 - 1.0 * \n",
    "            (SELECT COUNT(*) FROM df WHERE level = 1 AND result = 'lose') /\n",
    "            (SELECT COUNT(*) FROM df WHERE level >= 1 AND result IS NOT NULL)\n",
    "    END AS win_rate\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'level_5' AS level_label,\n",
    "    (SELECT COUNT(*) FROM df WHERE level = 5 AND result = 'lose'),\n",
    "    (SELECT COUNT(*) FROM df WHERE level >= 5 AND result IS NOT NULL),\n",
    "    CASE\n",
    "        WHEN (SELECT COUNT(*) FROM df WHERE level >= 5 AND result IS NOT NULL) = 0 THEN 0\n",
    "        ELSE 1.0 - 1.0 * \n",
    "            (SELECT COUNT(*) FROM df WHERE level = 5 AND result = 'lose') /\n",
    "            (SELECT COUNT(*) FROM df WHERE level >= 5 AND result IS NOT NULL)\n",
    "    END\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'level_10' AS level_label,\n",
    "    (SELECT COUNT(*) FROM df WHERE level = 10 AND result = 'lose'),\n",
    "    (SELECT COUNT(*) FROM df WHERE level >= 10 AND result IS NOT NULL),\n",
    "    CASE\n",
    "        WHEN (SELECT COUNT(*) FROM df WHERE level >= 10 AND result IS NOT NULL) = 0 THEN 0\n",
    "        ELSE 1.0 - 1.0 * \n",
    "            (SELECT COUNT(*) FROM df WHERE level = 10 AND result = 'lose') /\n",
    "            (SELECT COUNT(*) FROM df WHERE level >= 10 AND result IS NOT NULL)\n",
    "    END\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Th·ª±c thi\n",
    "filtered_df = pysqldf(query)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd05157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  level_label  lose_at_level  total_after_level  win_rate\n",
      "0     level_1              0            2421097  1.000000\n",
      "1     level_5            878            2265493  0.999612\n",
      "2    level_10          10734            2095775  0.994878\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn PostgreSQL\n",
    "engine = create_engine('postgresql+psycopg2://tienth:tienth@localhost:5434/ke_toan_dw')\n",
    "\n",
    "# C√¢u SQL: t√≠nh t·ªâ l·ªá chi·∫øn th·∫Øng ·ªü c√°c level 1, 5, 10\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    'level_1' AS level_label,\n",
    "    (SELECT COUNT(*) FROM event_logs_flat WHERE level = 1 AND result = 'lose') AS lose_at_level,\n",
    "    (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 1 AND result IS NOT NULL) AS total_after_level,\n",
    "    CASE\n",
    "        WHEN (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 1 AND result IS NOT NULL) = 0 THEN 0\n",
    "        ELSE 1.0 - 1.0 * \n",
    "            (SELECT COUNT(*) FROM event_logs_flat WHERE level = 1 AND result = 'lose') /\n",
    "            (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 1 AND result IS NOT NULL)\n",
    "    END AS win_rate\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'level_5' AS level_label,\n",
    "    (SELECT COUNT(*) FROM event_logs_flat WHERE level = 5 AND result = 'lose'),\n",
    "    (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 5 AND result IS NOT NULL),\n",
    "    CASE\n",
    "        WHEN (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 5 AND result IS NOT NULL) = 0 THEN 0\n",
    "        ELSE 1.0 - 1.0 * \n",
    "            (SELECT COUNT(*) FROM event_logs_flat WHERE level = 5 AND result = 'lose') /\n",
    "            (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 5 AND result IS NOT NULL)\n",
    "    END\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'level_10' AS level_label,\n",
    "    (SELECT COUNT(*) FROM event_logs_flat WHERE level = 10 AND result = 'lose'),\n",
    "    (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 10 AND result IS NOT NULL),\n",
    "    CASE\n",
    "        WHEN (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 10 AND result IS NOT NULL) = 0 THEN 0\n",
    "        ELSE 1.0 - 1.0 * \n",
    "            (SELECT COUNT(*) FROM event_logs_flat WHERE level = 10 AND result = 'lose') /\n",
    "            (SELECT COUNT(*) FROM event_logs_flat WHERE level >= 10 AND result IS NOT NULL)\n",
    "    END;\n",
    "\"\"\"\n",
    "\n",
    "# Th·ª±c thi SQL v√† hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "ket_qua = pd.read_sql_query(sql_query, con=engine)\n",
    "print(ket_qua)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc351cf8",
   "metadata": {},
   "source": [
    "K·∫øt qu·∫£ : \n",
    "\n",
    "level 1, 100% ng∆∞·ªùi ch∆°i th·∫Øng\n",
    "\n",
    "level 5: 99,9612% ng∆∞·ªùi ch∆°i th·∫Øng\n",
    "\n",
    "level 10 : 99,4878%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a9a4b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6523895f",
   "metadata": {},
   "source": [
    "b.T√≠nh t·ªâ l·ªá s·ª≠ d·ª•ng skill trung b√¨nh trong 1 v√°n ch∆°i c·ªßa nh·ªØng user ·ªü brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b32af7",
   "metadata": {},
   "source": [
    "logic x·ª≠ l√Ω:\n",
    "\n",
    "L·ªçc b·∫£n ghi c√≥:\n",
    "\n",
    "event_name = 'use_skill'\n",
    "\n",
    "geo.country = 'Brazil'\n",
    "\n",
    "M·ªói b·∫£n ghi event_name = 'use_skill' t∆∞∆°ng ·ª©ng v·ªõi 1 l·∫ßn d√πng skill --> count(*) tr√™n t·∫≠p d·ªØ li·ªáu ƒë√£ l·ªçc l√† t·ªïng s·ªë l·∫ßn d√πng skill\n",
    "\n",
    "M·ªói session ƒë∆∞·ª£c nh·∫≠n di·ªán b·ªüi c·∫∑p: user_id + ga_session_id --> ‚Üí L·∫•y t·∫≠p c√°c (user_id, ga_session_id) duy nh·∫•t ‚Üí ƒë·∫øm s·ªë l∆∞·ª£ng ‚Üí s·ªë session\n",
    "\n",
    "--> t·ªâ l·ªá s·ª≠ d·ª•ng skill trung b√¨nh tr√™n m·ªói session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   brazil_user_records\n",
      "0                11023\n",
      "   brazil_use_skill_count\n",
      "0                     399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# query = \"\"\" SELECT COUNT(*) AS brazil_user_records FROM df WHERE geo_country = 'Brazil';\"\"\"\n",
    "# result = pysqldf(query)\n",
    "\n",
    "# query2 = \"\"\" SELECT COUNT(*) AS brazil_use_skill_count FROM df WHERE event_name = 'use_skill' AND geo_country = 'Brazil'; \"\"\"\n",
    "# result2 = pysqldf(query2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71df994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_skill_usage_per_session  total_skill_usage_events  total_sessions\n",
      "0                     2.471935                     27216           11010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# K·∫øt n·ªëi t·ªõi PostgreSQL\n",
    "engine = create_engine('postgresql+psycopg2://tienth:tienth@localhost:5434/ke_toan_dw')\n",
    "\n",
    "# Truy v·∫•n SQL: t√≠nh t·ª∑ l·ªá s·ª≠ d·ª•ng skill trung b√¨nh tr√™n m·ªói session c·ªßa user ·ªü Brazil\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(*) * 1.0 / COUNT(DISTINCT user_id || '_' || ga_session_id) AS avg_skill_usage_per_session,\n",
    "    COUNT(*) AS total_skill_usage_events,\n",
    "    COUNT(DISTINCT user_id || '_' || ga_session_id) AS total_sessions\n",
    "FROM event_logs_flat\n",
    "WHERE event_name = 'use_skill'\n",
    "  AND geo_country = 'Brazil'\n",
    "  AND ga_session_id IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Th·ª±c thi v√† hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "df2 = pd.read_sql_query(sql_query, con=engine)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c5346",
   "metadata": {},
   "source": [
    "T·ªâ l·ªá s·ª≠ d·ª•ng skill trung b√¨nh trong 1 v√°n ch∆°i c·ªßa nh·ªØng user ·ªü brazil l√† 2.47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31486ba7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b1d42e",
   "metadata": {},
   "source": [
    "C. T√¨m t·ªâ l·ªá user c√≤n ·ªü l·∫°i ch∆°i game qua t·ª´ng level\n",
    "\n",
    "V·ªõi m·ªói level, ƒë·∫øm s·ªë l∆∞·ª£ng DISTINCT user_id ƒë√£ b·∫Øt ƒë·∫ßu level ƒë√≥ (level_start)\n",
    "\n",
    "ƒê·∫øm s·ªë l∆∞·ª£ng user duy nh·∫•t ·ªü m·ªói level (t·ª©c l√† user c√≤n ·ªü l·∫°i ƒë·∫øn level ƒë√≥).\n",
    "\n",
    "T√≠nh t·ª∑ l·ªá user c√≤n l·∫°i t·∫°i level N so v·ªõi s·ªë l∆∞·ª£ng user b·∫Øt ƒë·∫ßu t·∫°i level 1 (coi level 1 l√† ƒëi·ªÉm g·ªëc).\n",
    "\n",
    "T√≠nh retention rate qua t·ª´ng level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b6a7e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      level  user_count  retention_rate\n",
      "0         1       40914          1.0000\n",
      "1         2       35673          0.8719\n",
      "2         3       33199          0.8114\n",
      "3         4       29754          0.7272\n",
      "4         5       26888          0.6572\n",
      "...     ...         ...             ...\n",
      "3466  10746           1          0.0000\n",
      "3467  10747           1          0.0000\n",
      "3468  10748           1          0.0000\n",
      "3469  10749           1          0.0000\n",
      "3470  15401           1          0.0000\n",
      "\n",
      "[3471 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# K·∫øt n·ªëi ƒë·∫øn PostgreSQL\n",
    "engine = create_engine('postgresql+psycopg2://tienth:tienth@localhost:5434/ke_toan_dw')\n",
    "\n",
    "# C√¢u truy v·∫•n SQL t√≠nh retention rate qua t·ª´ng level\n",
    "sql_query = \"\"\"\n",
    "WITH users_per_level AS (\n",
    "    SELECT\n",
    "        level::int AS level,\n",
    "        COUNT(DISTINCT user_id) AS user_count\n",
    "    FROM event_logs_flat\n",
    "    WHERE event_name = 'level_start'\n",
    "      AND level IS NOT NULL\n",
    "    GROUP BY level::int\n",
    "),\n",
    "first_level AS (\n",
    "    SELECT user_count AS total_users_level_1\n",
    "    FROM users_per_level\n",
    "    WHERE level = 1\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    upl.level,\n",
    "    upl.user_count,\n",
    "    ROUND(upl.user_count * 1.0 / fl.total_users_level_1, 4) AS retention_rate\n",
    "FROM users_per_level upl\n",
    "JOIN first_level fl ON TRUE\n",
    "ORDER BY upl.level;\n",
    "\"\"\"\n",
    "\n",
    "# Th·ª±c thi c√¢u truy v·∫•n v√† ƒë·ªçc k·∫øt qu·∫£ v√†o DataFrame\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(df)\n",
    "\n",
    "# (T√πy ch·ªçn) V·∫Ω bi·ªÉu ƒë·ªì retention n·∫øu mu·ªën\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(df['level'], df['retention_rate'], marker='o')\n",
    "# plt.title('User Retention Rate by Level')\n",
    "# plt.xlabel('Level')\n",
    "# plt.ylabel('Retention Rate')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5f2cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
